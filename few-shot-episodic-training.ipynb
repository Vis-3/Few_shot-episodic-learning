{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":834066,"sourceType":"datasetVersion","datasetId":439215},{"sourceId":7477718,"sourceType":"datasetVersion","datasetId":4352631},{"sourceId":7478756,"sourceType":"datasetVersion","datasetId":4353232},{"sourceId":7505659,"sourceType":"datasetVersion","datasetId":4371022}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install easyfsl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-01T04:49:44.005795Z","iopub.execute_input":"2024-02-01T04:49:44.006125Z","iopub.status.idle":"2024-02-01T04:49:58.570650Z","shell.execute_reply.started":"2024-02-01T04:49:44.006096Z","shell.execute_reply":"2024-02-01T04:49:58.569643Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting easyfsl\n  Downloading easyfsl-1.5.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (3.7.4)\nRequirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (2.1.4)\nRequirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (2.1.2)\nRequirement already satisfied: torchvision>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (0.16.2)\nRequirement already satisfied: tqdm>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (4.66.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->easyfsl) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->easyfsl) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.7.0->easyfsl) (2.31.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->easyfsl) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.5.0->easyfsl) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.7.0->easyfsl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.7.0->easyfsl) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.7.0->easyfsl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.7.0->easyfsl) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.5.0->easyfsl) (1.3.0)\nDownloading easyfsl-1.5.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n\u001b[?25hInstalling collected packages: easyfsl\nSuccessfully installed easyfsl-1.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nimport copy\nimport pandas as pd\nimport numpy as np\nimport torch.nn.functional as F\nimport torch.utils.data as data\n\nimport torch\nimport torchvision\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import resnet18\nfrom tqdm import tqdm\nimport torchvision.models\nfrom PIL import Image\nfrom easyfsl.samplers import TaskSampler\nfrom easyfsl.utils import plot_images, sliding_average\nimport matplotlib.pyplot as plt\nfrom torchvision.io import read_image\nimport imageio.v2 as imageio\nimport re\nimport random\nfrom statistics import mean\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:49:58.572661Z","iopub.execute_input":"2024-02-01T04:49:58.572995Z","iopub.status.idle":"2024-02-01T04:50:05.938299Z","shell.execute_reply.started":"2024-02-01T04:49:58.572962Z","shell.execute_reply":"2024-02-01T04:50:05.937301Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"abnormal_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/train-abnormal.csv', names=['image_id', 'abnormal'])\nacl_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/train-acl.csv', names=['image_id', 'acl'])\nmeniscus_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/train-meniscus.csv', names=['image_id', 'meniscus'])\nmerged_df = pd.merge(acl_df, meniscus_df, how='inner', on='image_id')\nmerged_df = pd.merge(merged_df, abnormal_df, how='inner', on='image_id')\nmerged_df['label'] = merged_df['abnormal'] * 1 + merged_df['meniscus'] * 2 + merged_df['acl'] * 4\nmerged_df['image_id'] = merged_df['image_id'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\nlabel_mapping = {0: 0, 1: 1, 3: 2, 5: 3, 7: 4}\nmerged_df['label'] = merged_df['label'].map(label_mapping)\ntrain_df=merged_df","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:05.939488Z","iopub.execute_input":"2024-02-01T04:50:05.939880Z","iopub.status.idle":"2024-02-01T04:50:06.020843Z","shell.execute_reply.started":"2024-02-01T04:50:05.939855Z","shell.execute_reply":"2024-02-01T04:50:06.019874Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Label\n# 0 - No abnormility, acl or meniscus\n# 1 - only abnormility\n# 2 - abnormility and meniscus\n# 3 - abnormility and acl\n# 4 - abnormility and meniscus and acl","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.023335Z","iopub.execute_input":"2024-02-01T04:50:06.023702Z","iopub.status.idle":"2024-02-01T04:50:06.027945Z","shell.execute_reply.started":"2024-02-01T04:50:06.023671Z","shell.execute_reply":"2024-02-01T04:50:06.026820Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.029212Z","iopub.execute_input":"2024-02-01T04:50:06.029565Z","iopub.status.idle":"2024-02-01T04:50:06.049121Z","shell.execute_reply.started":"2024-02-01T04:50:06.029533Z","shell.execute_reply":"2024-02-01T04:50:06.048253Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  image_id  acl  meniscus  abnormal  label\n0     0000    0         0         1      1\n1     0001    1         1         1      4\n2     0002    0         0         1      1\n3     0003    0         1         1      2\n4     0004    0         0         1      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>acl</th>\n      <th>meniscus</th>\n      <th>abnormal</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0001</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.050416Z","iopub.execute_input":"2024-02-01T04:50:06.050712Z","iopub.status.idle":"2024-02-01T04:50:06.062882Z","shell.execute_reply.started":"2024-02-01T04:50:06.050688Z","shell.execute_reply":"2024-02-01T04:50:06.061997Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"label\n1    433\n2    272\n0    217\n4    125\n3     83\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"\n# # Read CSV files and drop rows with label 0\n# abnormal_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/train-abnormal.csv', names=['image_id', 'label']).query('label != 0')\n# acl_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/train-acl.csv', names=['image_id', 'label']).query('label != 0')\n# meniscus_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/train-meniscus.csv', names=['image_id', 'label']).query('label != 0')\n\n# # Assign labels to each DataFrame\n# abnormal_df['label'] = 0\n# acl_df['label'] = 1\n# meniscus_df['label'] = 2\n\n# acl_df['image_id'] = acl_df['image_id'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\n# meniscus_df['image_id'] = meniscus_df['image_id'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\n# abnormal_df['image_id'] = abnormal_df['image_id'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\n\n# # Merge DataFrames with preference to abnormal and then acl\n# train_df = pd.concat([acl_df, meniscus_df, abnormal_df], ignore_index=True, sort=False)\n\n# # Drop duplicates and keep the first occurrence (preference to abnormal and then acl)\n# train_df = train_df.drop_duplicates(subset='image_id', keep='first')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.064144Z","iopub.execute_input":"2024-02-01T04:50:06.064450Z","iopub.status.idle":"2024-02-01T04:50:06.071397Z","shell.execute_reply.started":"2024-02-01T04:50:06.064414Z","shell.execute_reply":"2024-02-01T04:50:06.070434Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# abnormal_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/valid-abnormal.csv', names=['image_id', 'label']).query('label != 0')\n# acl_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/valid-acl.csv', names=['image_id', 'label']).query('label != 0')\n# meniscus_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/valid-meniscus.csv', names=['image_id', 'label']).query('label != 0')\n\n# # Assign labels to each DataFrame\n# abnormal_df['label'] = 0\n# acl_df['label'] = 1\n# meniscus_df['label'] = 2\n\n# acl_df['image_id'] = acl_df['image_id'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\n# meniscus_df['image_id'] = meniscus_df['image_id'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\n# abnormal_df['image_id'] = abnormal_df['image_id'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\n\n# # Merge DataFrames with preference to abnormal and then acl\n# test_df = pd.concat([acl_df, meniscus_df, abnormal_df], ignore_index=True, sort=False)\n\n# # Drop duplicates and keep the first occurrence (preference to abnormal and then acl)\n# test_df = test_df.drop_duplicates(subset='image_id', keep='first')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.072547Z","iopub.execute_input":"2024-02-01T04:50:06.073574Z","iopub.status.idle":"2024-02-01T04:50:06.084455Z","shell.execute_reply.started":"2024-02-01T04:50:06.073550Z","shell.execute_reply":"2024-02-01T04:50:06.083580Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# train_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.085695Z","iopub.execute_input":"2024-02-01T04:50:06.086017Z","iopub.status.idle":"2024-02-01T04:50:06.098221Z","shell.execute_reply.started":"2024-02-01T04:50:06.085984Z","shell.execute_reply":"2024-02-01T04:50:06.097199Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"abnormal_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/valid-abnormal.csv', names=['image_id', 'abnormal'])\nacl_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/valid-acl.csv', names=['image_id', 'acl'])\nmeniscus_df = pd.read_csv('/kaggle/input/mrnet-v1/MRNet-v1.0/valid-meniscus.csv', names=['image_id', 'meniscus'])\nmerged_df = pd.merge(acl_df, meniscus_df, how='inner', on='image_id')\nmerged_df = pd.merge(merged_df, abnormal_df, how='inner', on='image_id')\nmerged_df['label'] = merged_df['abnormal'] * 1 + merged_df['meniscus'] * 2 + merged_df['acl'] * 4\nmerged_df['image_id'] = merged_df['image_id'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\nlabel_mapping = {0: 0, 1: 1, 3: 2, 5: 3, 7: 4}\nmerged_df['label'] = merged_df['label'].map(label_mapping)\ntest_df=merged_df","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.102552Z","iopub.execute_input":"2024-02-01T04:50:06.103148Z","iopub.status.idle":"2024-02-01T04:50:06.144390Z","shell.execute_reply.started":"2024-02-01T04:50:06.103117Z","shell.execute_reply":"2024-02-01T04:50:06.143577Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.145521Z","iopub.execute_input":"2024-02-01T04:50:06.145794Z","iopub.status.idle":"2024-02-01T04:50:06.155346Z","shell.execute_reply.started":"2024-02-01T04:50:06.145771Z","shell.execute_reply":"2024-02-01T04:50:06.154360Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"  image_id  acl  meniscus  abnormal  label\n0     1130    0         0         0      0\n1     1131    0         0         0      0\n2     1132    0         0         0      0\n3     1133    0         0         0      0\n4     1134    0         0         0      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>acl</th>\n      <th>meniscus</th>\n      <th>abnormal</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1130</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1131</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1132</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1133</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1134</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.156446Z","iopub.execute_input":"2024-02-01T04:50:06.156725Z","iopub.status.idle":"2024-02-01T04:50:06.168061Z","shell.execute_reply.started":"2024-02-01T04:50:06.156701Z","shell.execute_reply":"2024-02-01T04:50:06.167100Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"label\n4    31\n0    25\n3    23\n2    21\n1    20\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_train = train_df[train_df['label'].isin([1, 2,4])]\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.170002Z","iopub.execute_input":"2024-02-01T04:50:06.170323Z","iopub.status.idle":"2024-02-01T04:50:06.177904Z","shell.execute_reply.started":"2024-02-01T04:50:06.170291Z","shell.execute_reply":"2024-02-01T04:50:06.177117Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.178860Z","iopub.execute_input":"2024-02-01T04:50:06.179438Z","iopub.status.idle":"2024-02-01T04:50:06.192580Z","shell.execute_reply.started":"2024-02-01T04:50:06.179407Z","shell.execute_reply":"2024-02-01T04:50:06.191723Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"label\n1    433\n2    272\n4    125\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_test = test_df[test_df['label'].isin([0, 3])]","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.193683Z","iopub.execute_input":"2024-02-01T04:50:06.193954Z","iopub.status.idle":"2024-02-01T04:50:06.201228Z","shell.execute_reply.started":"2024-02-01T04:50:06.193933Z","shell.execute_reply":"2024-02-01T04:50:06.200389Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"selected_classes = [0,3]\n\n# Initialize an empty DataFrame for the sampled data\nsampled_df = pd.DataFrame()\n\n# Iterate through each selected class and sample 20% of data from each class\nfor class_label in selected_classes:\n    class_data = train_df[train_df['label'] == class_label]\n    sampled_class_data = class_data.sample(frac=0.3, random_state=42)  # Adjust the random_state if needed\n    sampled_df = pd.concat([sampled_df, sampled_class_data])","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.202296Z","iopub.execute_input":"2024-02-01T04:50:06.202621Z","iopub.status.idle":"2024-02-01T04:50:06.216530Z","shell.execute_reply.started":"2024-02-01T04:50:06.202578Z","shell.execute_reply":"2024-02-01T04:50:06.215769Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_valid=sampled_df","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.217680Z","iopub.execute_input":"2024-02-01T04:50:06.218071Z","iopub.status.idle":"2024-02-01T04:50:06.223820Z","shell.execute_reply.started":"2024-02-01T04:50:06.218042Z","shell.execute_reply":"2024-02-01T04:50:06.222912Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.224870Z","iopub.execute_input":"2024-02-01T04:50:06.226657Z","iopub.status.idle":"2024-02-01T04:50:06.236516Z","shell.execute_reply.started":"2024-02-01T04:50:06.226631Z","shell.execute_reply":"2024-02-01T04:50:06.235509Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"label\n1    433\n2    272\n4    125\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_valid['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.237659Z","iopub.execute_input":"2024-02-01T04:50:06.237943Z","iopub.status.idle":"2024-02-01T04:50:06.247763Z","shell.execute_reply.started":"2024-02-01T04:50:06.237913Z","shell.execute_reply":"2024-02-01T04:50:06.246747Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"label\n0    65\n3    25\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def interpolate_mri_images(images, num_interpolated_slices=15, interpolation_ratio=0.8):\n    \n    # Calculate the number of original slices\n    num_original_slices = images.shape[0]\n\n    # Calculate the interpolation step size\n    interpolation_step = (num_original_slices - 1) / (num_interpolated_slices - 1)\n\n    # Create an array to store the interpolated images\n    interpolated_images = []\n\n    # Iterate through each interpolated slice\n    for i in range(num_interpolated_slices):\n        # Calculate the index of the nearest original slices for interpolation\n        base_index = int(i * interpolation_step)\n        next_index = min(base_index + 1, num_original_slices - 1)\n\n        # Extract the original slices for interpolation\n        base_slice = images[base_index]\n        next_slice = images[next_index]\n\n        # Perform linear interpolation\n        interpolated_slice = (1 - interpolation_ratio) * base_slice + interpolation_ratio * next_slice\n\n        # Append the interpolated slice to the result\n        interpolated_images.append(interpolated_slice)\n\n    # Convert the result to a NumPy array\n    interpolated_images = np.array(interpolated_images)\n\n    return interpolated_images","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.248977Z","iopub.execute_input":"2024-02-01T04:50:06.249354Z","iopub.status.idle":"2024-02-01T04:50:06.257427Z","shell.execute_reply.started":"2024-02-01T04:50:06.249324Z","shell.execute_reply":"2024-02-01T04:50:06.256663Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import cv2\ndef apply_transformations(image_array):\n    transformed_frames = []\n    for frame in image_array:\n        # Resize\n        resized_frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)\n\n        # Random horizontal flip\n        if np.random.rand() < 0.5:\n            resized_frame = cv2.flip(resized_frame, 1)\n\n        # Random vertical flip\n        if np.random.rand() < 0.5:\n            resized_frame = cv2.flip(resized_frame, 0)\n\n        # Random rotation\n        angle = np.random.uniform(-45, 45)\n        rows, cols = resized_frame.shape\n        rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n        rotated_frame = cv2.warpAffine(resized_frame, rotation_matrix, (cols, rows))\n\n        # Random affine transformation\n        scale = 1.0\n        angle = np.random.uniform(-45, 45)\n        translation = (np.random.uniform(-0.1, 0.1) * cols, np.random.uniform(-0.1, 0.1) * rows)\n        affine_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, scale)\n        affine_matrix[:, 2] += translation\n        transformed_frame = cv2.warpAffine(rotated_frame, affine_matrix, (cols, rows))\n\n        transformed_frames.append(transformed_frame)\n       \n    # Convert to tensor\n    transformed_frames = np.array(transformed_frames)\n\n    return transformed_frames\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.258309Z","iopub.execute_input":"2024-02-01T04:50:06.258602Z","iopub.status.idle":"2024-02-01T04:50:06.461994Z","shell.execute_reply.started":"2024-02-01T04:50:06.258580Z","shell.execute_reply":"2024-02-01T04:50:06.461278Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import cv2\ndef apply_transformations(image_array):\n    transformed_frames = []\n    for frame in image_array:\n        # Resize\n        resized_frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)\n\n        # Random horizontal flip\n        if np.random.rand() < 0.5:\n            resized_frame = cv2.flip(resized_frame, 1)\n\n        # Random vertical flip\n        if np.random.rand() < 0.5:\n            resized_frame = cv2.flip(resized_frame, 0)\n\n        # Random rotation\n        angle = np.random.uniform(-45, 45)\n        rows, cols = resized_frame.shape\n        rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n        rotated_frame = cv2.warpAffine(resized_frame, rotation_matrix, (cols, rows))\n\n        # Random affine transformation\n        scale = 1.0\n        angle = np.random.uniform(-45, 45)\n        translation = (np.random.uniform(-0.1, 0.1) * cols, np.random.uniform(-0.1, 0.1) * rows)\n        affine_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, scale)\n        affine_matrix[:, 2] += translation\n        transformed_frame = cv2.warpAffine(rotated_frame, affine_matrix, (cols, rows))\n\n        transformed_frames.append(transformed_frame)\n       \n    # Convert to tensor\n    transformed_frames = np.array(transformed_frames)\n\n    return transformed_frames\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.463151Z","iopub.execute_input":"2024-02-01T04:50:06.463531Z","iopub.status.idle":"2024-02-01T04:50:06.473325Z","shell.execute_reply.started":"2024-02-01T04:50:06.463497Z","shell.execute_reply":"2024-02-01T04:50:06.472425Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def apply_transformations_test(image_array):\n    transformed_frames = []\n    for frame in image_array:\n        # Resize\n        resized_frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)\n\n        # Random horizontal flip\n        if np.random.rand() < 0.5:\n            resized_frame = cv2.flip(resized_frame, 1)\n\n        transformed_frames.append(resized_frame)\n       \n    # Convert to tensor\n    transformed_frames = np.array(transformed_frames)\n\n    return transformed_frames","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.474613Z","iopub.execute_input":"2024-02-01T04:50:06.475333Z","iopub.status.idle":"2024-02-01T04:50:06.487063Z","shell.execute_reply.started":"2024-02-01T04:50:06.475298Z","shell.execute_reply":"2024-02-01T04:50:06.486239Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class MRDataset(data.Dataset):\n    def __init__(self, root_dir,plane, train=\"train\" ,transform=None):\n        self.plane = plane\n        self.transform = transform\n        self.train = train\n        if self.train==\"train\":\n            self.records = df_train\n            self.img_dir = root_dir+ 'train/{0}/'.format(plane)\n        elif self.train==\"valid\":\n            self.records = df_valid\n            self.img_dir = root_dir+ 'train/{0}/'.format(plane)\n        \n        else:\n            self.records = df_test\n            self.img_dir = root_dir+ 'valid/{0}/'.format(plane)\n        self.paths = [self.img_dir + filename +\n                      '.npy' for filename in self.records['image_id'].tolist()]\n        self.labels = self.records['label'].tolist()\n        \n    def __len__(self):\n        return len(self.paths)\n    \n    def get_labels(self):\n        return self.labels\n    \n    def __getitem__(self, index):\n        img_path = self.paths[index]\n        image =  np.load(img_path)\n        label = self.labels[index]\n        image=interpolate_mri_images(image)\n        if self.transform:\n            if self.train==\"train\":\n                image = apply_transformations(image)\n            else:\n                image = apply_transformations_test(image)\n        image = (image - 58.09) / 49.73\n        image = np.stack((image,)*1, axis=3)\n        image = torch.FloatTensor(image)\n        image=image.reshape(image.shape[3],image.shape[0],image.shape[1],image.shape[2])\n        return image,label","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.488196Z","iopub.execute_input":"2024-02-01T04:50:06.488500Z","iopub.status.idle":"2024-02-01T04:50:06.499982Z","shell.execute_reply.started":"2024-02-01T04:50:06.488475Z","shell.execute_reply":"2024-02-01T04:50:06.498839Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"root_dir = \"/kaggle/input/mrnet-v1/MRNet-v1.0/\"","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.501351Z","iopub.execute_input":"2024-02-01T04:50:06.502006Z","iopub.status.idle":"2024-02-01T04:50:06.512479Z","shell.execute_reply.started":"2024-02-01T04:50:06.501972Z","shell.execute_reply":"2024-02-01T04:50:06.511581Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"mrnet_dataset = MRDataset(root_dir,plane=\"axial\",train=\"train\",transform=True)\n\n# Create a DataLoader for your dataset\nbatch_size = 1\ndataloader = DataLoader(dataset=mrnet_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.513626Z","iopub.execute_input":"2024-02-01T04:50:06.514208Z","iopub.status.idle":"2024-02-01T04:50:06.521614Z","shell.execute_reply.started":"2024-02-01T04:50:06.514175Z","shell.execute_reply":"2024-02-01T04:50:06.520732Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"test_features, test_labels = next(iter(dataloader))\nprint(f\"Feature batch shape: {test_features.size()}\")\nprint(f\"Labels batch shape: {test_labels.size()}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.522537Z","iopub.execute_input":"2024-02-01T04:50:06.522828Z","iopub.status.idle":"2024-02-01T04:50:06.715413Z","shell.execute_reply.started":"2024-02-01T04:50:06.522808Z","shell.execute_reply":"2024-02-01T04:50:06.714499Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Feature batch shape: torch.Size([1, 1, 15, 224, 224])\nLabels batch shape: torch.Size([1])\n","output_type":"stream"}]},{"cell_type":"code","source":"mrnet_dataset = MRDataset(root_dir,plane=\"axial\",train=\"valid\",transform=True)\n\n# Create a DataLoader for your dataset\nbatch_size = 1\ndataloader = DataLoader(dataset=mrnet_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.721344Z","iopub.execute_input":"2024-02-01T04:50:06.721672Z","iopub.status.idle":"2024-02-01T04:50:06.727503Z","shell.execute_reply.started":"2024-02-01T04:50:06.721645Z","shell.execute_reply":"2024-02-01T04:50:06.726440Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_features, test_labels = next(iter(dataloader))\nprint(f\"Feature batch shape: {test_features.size()}\")\nprint(f\"Labels batch shape: {test_labels.size()}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.728698Z","iopub.execute_input":"2024-02-01T04:50:06.729020Z","iopub.status.idle":"2024-02-01T04:50:06.817885Z","shell.execute_reply.started":"2024-02-01T04:50:06.728991Z","shell.execute_reply":"2024-02-01T04:50:06.816751Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Feature batch shape: torch.Size([1, 1, 15, 224, 224])\nLabels batch shape: torch.Size([1])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training a Meta Trainer","metadata":{}},{"cell_type":"code","source":"root_dir = \"/kaggle/input/mrnet-v1/MRNet-v1.0/\"","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.818972Z","iopub.execute_input":"2024-02-01T04:50:06.819239Z","iopub.status.idle":"2024-02-01T04:50:06.823325Z","shell.execute_reply.started":"2024-02-01T04:50:06.819215Z","shell.execute_reply":"2024-02-01T04:50:06.822387Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_set= MRDataset(root_dir,plane=\"axial\",train=\"train\", transform=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.824508Z","iopub.execute_input":"2024-02-01T04:50:06.824831Z","iopub.status.idle":"2024-02-01T04:50:06.832112Z","shell.execute_reply.started":"2024-02-01T04:50:06.824807Z","shell.execute_reply":"2024-02-01T04:50:06.831317Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"val_set = MRDataset(root_dir,plane=\"axial\",train=\"valid\", transform=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.833107Z","iopub.execute_input":"2024-02-01T04:50:06.833397Z","iopub.status.idle":"2024-02-01T04:50:06.842900Z","shell.execute_reply.started":"2024-02-01T04:50:06.833349Z","shell.execute_reply":"2024-02-01T04:50:06.842018Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"n_tasks_per_epoch = 500\nn_validation_tasks = 100\n\ntrain_sampler = TaskSampler(\n    train_set, n_way=3, n_shot=5, n_query=10, n_tasks=n_tasks_per_epoch\n)\ntrain_loader = DataLoader(\n    train_set,\n    batch_sampler=train_sampler,\n    num_workers=4,\n    pin_memory=True,\n    collate_fn=train_sampler.episodic_collate_fn,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:06.843962Z","iopub.execute_input":"2024-02-01T04:50:06.844267Z","iopub.status.idle":"2024-02-01T04:50:06.853334Z","shell.execute_reply.started":"2024-02-01T04:50:06.844243Z","shell.execute_reply":"2024-02-01T04:50:06.852385Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"val_sampler = TaskSampler(\n    val_set, n_way=2, n_shot=5, n_query=10, n_tasks=n_validation_tasks\n)\nval_loader = DataLoader(\n    val_set,\n    batch_sampler=val_sampler,\n    num_workers=4,\n    pin_memory=True,\n    collate_fn=val_sampler.episodic_collate_fn,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:51:53.523830Z","iopub.execute_input":"2024-02-01T04:51:53.524668Z","iopub.status.idle":"2024-02-01T04:51:53.529783Z","shell.execute_reply.started":"2024-02-01T04:51:53.524635Z","shell.execute_reply":"2024-02-01T04:51:53.528670Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# from torchvision.models import video\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:07.367604Z","iopub.status.idle":"2024-02-01T04:50:07.367918Z","shell.execute_reply.started":"2024-02-01T04:50:07.367763Z","shell.execute_reply":"2024-02-01T04:50:07.367776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class PrototypicalNetworks(nn.Module):\n#     def __init__(self, backbone: nn.Module):\n#         super(PrototypicalNetworks, self).__init__()\n#         self.backbone = backbone\n\n#     def forward(\n#         self,\n#         support_images: torch.Tensor,\n#         support_labels: torch.Tensor,\n#         query_images: torch.Tensor,\n#     ) -> torch.Tensor:\n#         \"\"\"\n#         Predict query labels using labeled support images.\n#         \"\"\"\n#         # Extract the features of support and query images\n#         z_support = self.backbone.forward(support_images)\n#         z_query = self.backbone.forward(query_images)\n\n#         # Infer the number of different classes from the labels of the support set\n#         n_way = len(torch.unique(support_labels))\n#         # Prototype i is the mean of all instances of features corresponding to labels == i\n#         z_proto = torch.cat(\n#             [\n#                 z_support[torch.nonzero(support_labels == label)].mean(0)\n#                 for label in range(n_way)\n#             ]\n#         )\n\n#         # Compute the euclidean distance from queries to prototypes\n#         dists = torch.cdist(z_query, z_proto)\n\n#         # And here is the super complicated operation to transform those distances into classification scores!\n#         scores = -dists\n#         return scores\n\n\n# convolutional_network = video.r3d_18(pretrained=True)\n\n# convolutional_network.fc = nn.Flatten()\n# convolutional_network = nn.DataParallel(convolutional_network)\n# print(convolutional_network)\n\n# model = PrototypicalNetworks(convolutional_network).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:50:07.369016Z","iopub.status.idle":"2024-02-01T04:50:07.369343Z","shell.execute_reply.started":"2024-02-01T04:50:07.369182Z","shell.execute_reply":"2024-02-01T04:50:07.369196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport math\nfrom functools import partial\n\n__all__ = [\n    'ResNet', 'resnet10', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n    'resnet152', 'resnet200'\n]\n\n\ndef conv3x3x3(in_planes, out_planes, stride=1, dilation=1):\n    # 3x3x3 convolution with padding\n    return nn.Conv3d(\n        in_planes,\n        out_planes,\n        kernel_size=3,\n        dilation=dilation,\n        stride=stride,\n        padding=dilation,\n        bias=False)\n\n\ndef downsample_basic_block(x, planes, stride, no_cuda=False):\n    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n    zero_pads = torch.Tensor(\n        out.size(0), planes - out.size(1), out.size(2), out.size(3),\n        out.size(4)).zero_()\n    if not no_cuda:\n        if isinstance(out.data, torch.cuda.FloatTensor):\n            zero_pads = zero_pads.cuda()\n\n    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n\n    return out\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, dilation=dilation)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3x3(planes, planes, dilation=dilation)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.downsample = downsample\n        self.stride = stride\n        self.dilation = dilation\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm3d(planes)\n        self.conv2 = nn.Conv3d(\n            planes, planes, kernel_size=3, stride=stride, dilation=dilation, padding=dilation, bias=False)\n        self.bn2 = nn.BatchNorm3d(planes)\n        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm3d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n        self.dilation = dilation\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass upsample(nn.Module):\n    def forward(self, inp):\n        return F.interpolate(inp, scale_factor = 2)\n\nclass ResNet(nn.Module):\n\n    def __init__(self,\n                 block,\n                 layers,\n                 num_seg_classes=2,\n                 shortcut_type='B',\n                 no_cuda = False):\n        self.inplanes = 64\n        self.no_cuda = no_cuda\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv3d(\n            1,\n            64,\n            kernel_size=7,\n            stride=(2, 2, 2),\n            padding=(3, 3, 3),\n            bias=False)\n            \n        self.bn1 = nn.BatchNorm3d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n        self.layer2 = self._make_layer(\n            block, 128, layers[1], shortcut_type, stride=2)\n        self.layer3 = self._make_layer(\n            block, 256, layers[2], shortcut_type, stride=1, dilation=2)\n        self.layer4 = self._make_layer(\n            block, 512, layers[3], shortcut_type, stride=1, dilation=4)\n\n        self.conv_seg = nn.Sequential(\n                                        upsample(),\n                                        nn.ConvTranspose3d(\n                                        512 * block.expansion,\n                                        32,\n                                        2,\n                                        stride=2\n                                        ),\n                                        nn.BatchNorm3d(32),\n                                        nn.ReLU(inplace=True),\n                                        upsample(),\n                                        nn.Conv3d(\n                                        32,\n                                        32,\n                                        kernel_size=3,\n                                        stride=(1, 1, 1),\n                                        padding=(1, 1, 1),\n                                        bias=False), \n                                        nn.BatchNorm3d(32),\n                                        nn.ReLU(inplace=True),\n                                        nn.Conv3d(\n                                        32,\n                                        num_seg_classes,\n                                        kernel_size=1,\n                                        stride=(1, 1, 1),\n                                        bias=False),\n                                        nn.Sigmoid() \n                                        )\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                m.weight = nn.init.kaiming_normal_(m.weight, mode='fan_out')\n            elif isinstance(m, nn.BatchNorm3d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1, dilation=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            if shortcut_type == 'A':\n                downsample = partial(\n                    downsample_basic_block,\n                    planes=planes * block.expansion,\n                    stride=stride,\n                    no_cuda=self.no_cuda)\n            else:\n                downsample = nn.Sequential(\n                    nn.Conv3d(\n                        self.inplanes,\n                        planes * block.expansion,\n                        kernel_size=1,\n                        stride=stride,\n                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride=stride, dilation=dilation, downsample=downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, dilation=dilation))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        #print(x.shape)\n        x = self.conv_seg(x)\n\n        return x\n\ndef resnet10(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n    return model\n\n\ndef resnet18(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    return model\n\n\ndef resnet34(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    return model\n\n\ndef resnet50(**kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    return model\n\n\ndef resnet101(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    return model\n\n\ndef resnet152(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    return model\n\n\ndef resnet200(**kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:52:02.379505Z","iopub.execute_input":"2024-02-01T04:52:02.379841Z","iopub.status.idle":"2024-02-01T04:52:02.421498Z","shell.execute_reply.started":"2024-02-01T04:52:02.379813Z","shell.execute_reply":"2024-02-01T04:52:02.420533Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def trim_state_dict_name(state_dict):\n    for k in list(state_dict.keys()):\n        if k.startswith('module.'):\n            # remove prefix\n            state_dict[k[len(\"module.\"):]] = state_dict[k]\n            del state_dict[k]\n    return state_dict","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:52:02.423036Z","iopub.execute_input":"2024-02-01T04:52:02.423302Z","iopub.status.idle":"2024-02-01T04:52:02.440627Z","shell.execute_reply.started":"2024-02-01T04:52:02.423279Z","shell.execute_reply":"2024-02-01T04:52:02.439696Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def get_feature_extractor():\n    model = resnet50(shortcut_type='B')\n    model.conv_seg = nn.Flatten()\n    # download pretrained weight from https://drive.google.com/file/d/13tnSvXY7oDIEloNFiGTsjUIYfS3g3BfG/view?usp=sharing\n    ckpt = torch.load(\"/kaggle/input/resnet50-add/resnet_50_23dataset.pth\")\n    ckpt = trim_state_dict_name(ckpt[\"state_dict\"])\n    model.load_state_dict(ckpt)\n    model = nn.DataParallel(model).cuda()\n    model.eval()\n    print(\"Feature extractor weights loaded\")\n    return model\n\nmodel = get_feature_extractor()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:52:02.441708Z","iopub.execute_input":"2024-02-01T04:52:02.441980Z","iopub.status.idle":"2024-02-01T04:52:06.480074Z","shell.execute_reply.started":"2024-02-01T04:52:02.441956Z","shell.execute_reply":"2024-02-01T04:52:06.479089Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Feature extractor weights loaded\n","output_type":"stream"}]},{"cell_type":"code","source":"from easyfsl.methods import PrototypicalNetworks, FewShotClassifier\nconvolutional_network = model\nfew_shot_classifier = PrototypicalNetworks(convolutional_network).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:52:06.482599Z","iopub.execute_input":"2024-02-01T04:52:06.482893Z","iopub.status.idle":"2024-02-01T04:52:06.491022Z","shell.execute_reply.started":"2024-02-01T04:52:06.482869Z","shell.execute_reply":"2024-02-01T04:52:06.490132Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# class PrototypicalNetworks(nn.Module):\n#     def __init__(self, backbone: nn.Module):\n#         super(PrototypicalNetworks, self).__init__()\n#         self.backbone = backbone\n\n#     def forward(\n#         self,\n#         support_images: torch.Tensor,\n#         support_labels: torch.Tensor,\n#         query_images: torch.Tensor,\n#     ) -> torch.Tensor:\n#         \"\"\"\n#         Predict query labels using labeled support images.\n#         \"\"\"\n#         # Extract the features of support and query images\n#         z_support = self.backbone.forward(support_images)\n#         z_query = self.backbone.forward(query_images)\n\n#         # Infer the number of different classes from the labels of the support set\n#         n_way = len(torch.unique(support_labels))\n#         # Prototype i is the mean of all instances of features corresponding to labels == i\n#         z_proto = torch.cat(\n#             [\n#                 z_support[torch.nonzero(support_labels == label)].mean(0)\n#                 for label in range(n_way)\n#             ]\n#         )\n\n#         # Compute the euclidean distance from queries to prototypes\n#         dists = torch.cdist(z_query, z_proto)\n\n#         # And here is the super complicated operation to transform those distances into classification scores!\n#         scores = -dists\n#         return scores\n\n\n# convolutional_network = model\n# print(convolutional_network)\n\n# model = PrototypicalNetworks(convolutional_network).cuda()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:52:06.492057Z","iopub.execute_input":"2024-02-01T04:52:06.492313Z","iopub.status.idle":"2024-02-01T04:52:06.499326Z","shell.execute_reply.started":"2024-02-01T04:52:06.492286Z","shell.execute_reply":"2024-02-01T04:52:06.498635Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from torch.optim import SGD, Optimizer\nfrom torch.optim.lr_scheduler import MultiStepLR\nfrom torch.utils.tensorboard import SummaryWriter\nfrom pathlib import Path\n\nLOSS_FUNCTION = nn.CrossEntropyLoss()\n\nn_epochs = 10\nscheduler_milestones = [120, 160]\nscheduler_gamma = 0.1\nlearning_rate = 1e-2\ntb_logs_dir = Path(\".\")\n\ntrain_optimizer = SGD(\n    few_shot_classifier.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n)\ntrain_scheduler = MultiStepLR(\n    train_optimizer,\n    milestones=scheduler_milestones,\n    gamma=scheduler_gamma,\n)\n\ntb_writer = SummaryWriter(log_dir=str(tb_logs_dir))","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:52:06.500332Z","iopub.execute_input":"2024-02-01T04:52:06.500641Z","iopub.status.idle":"2024-02-01T04:52:18.144496Z","shell.execute_reply.started":"2024-02-01T04:52:06.500618Z","shell.execute_reply":"2024-02-01T04:52:18.143331Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"2024-02-01 04:52:08.893635: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-01 04:52:08.893743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-01 04:52:09.057058: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def training_epoch(\n    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n):\n    all_loss = []\n    model.train()\n    with tqdm(\n        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n    ) as tqdm_train:\n        for episode_index, (\n            support_images,\n            support_labels,\n            query_images,\n            query_labels,\n            _,\n        ) in tqdm_train:\n            optimizer.zero_grad()\n            model.process_support_set(\n                support_images.cuda(), support_labels.cuda()\n            )\n            classification_scores = model(query_images.cuda())\n\n            loss = LOSS_FUNCTION(classification_scores, query_labels.cuda())\n            loss.backward()\n            optimizer.step()\n\n            all_loss.append(loss.item())\n\n            tqdm_train.set_postfix(loss=mean(all_loss))\n\n    return mean(all_loss)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T04:52:18.145789Z","iopub.execute_input":"2024-02-01T04:52:18.146841Z","iopub.status.idle":"2024-02-01T04:52:18.156088Z","shell.execute_reply.started":"2024-02-01T04:52:18.146811Z","shell.execute_reply":"2024-02-01T04:52:18.153265Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from easyfsl.utils import evaluate\n\n\nbest_state = few_shot_classifier.state_dict()\nbest_validation_accuracy = 0.0\nfor epoch in range(n_epochs):\n    print(f\"Epoch {epoch}\")\n    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n    validation_accuracy = evaluate(\n        few_shot_classifier, val_loader, device=\"cuda\", tqdm_prefix=\"Validation\"\n    )\n\n    if validation_accuracy > best_validation_accuracy:\n        best_validation_accuracy = validation_accuracy\n        best_state = copy.deepcopy(few_shot_classifier.state_dict())\n        # state_dict() returns a reference to the still evolving model's state so we deepcopy\n        # https://pytorch.org/tutorials/beginner/saving_loading_models\n        print(\"Ding ding ding! We found a new best model!\")\n\n    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n\n    # Warn the scheduler that we did an epoch\n    # so it knows when to decrease the learning rate\n    train_scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T11:30:48.385502Z","iopub.execute_input":"2024-02-01T11:30:48.385833Z","iopub.status.idle":"2024-02-01T11:30:53.756798Z","shell.execute_reply.started":"2024-02-01T11:30:48.385809Z","shell.execute_reply":"2024-02-01T11:30:53.755462Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Epoch 0\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/500 [00:05<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[61], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     average_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfew_shot_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     validation_accuracy \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[1;32m     10\u001b[0m         few_shot_classifier, val_loader, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, tqdm_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validation_accuracy \u001b[38;5;241m>\u001b[39m best_validation_accuracy:\n","Cell \u001b[0;32mIn[42], line 22\u001b[0m, in \u001b[0;36mtraining_epoch\u001b[0;34m(model, data_loader, optimizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mprocess_support_set(\n\u001b[1;32m     18\u001b[0m     support_images\u001b[38;5;241m.\u001b[39mcuda(), support_labels\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m classification_scores \u001b[38;5;241m=\u001b[39m model(query_images\u001b[38;5;241m.\u001b[39mcuda())\n\u001b[0;32m---> 22\u001b[0m loss \u001b[38;5;241m=\u001b[39m LOSS_FUNCTION(classification_scores, \u001b[43mquery_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"few_shot_classifier.load_state_dict(best_state)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T11:30:58.117834Z","iopub.execute_input":"2024-02-01T11:30:58.118591Z","iopub.status.idle":"2024-02-01T11:30:58.137596Z","shell.execute_reply.started":"2024-02-01T11:30:58.118551Z","shell.execute_reply":"2024-02-01T11:30:58.136471Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"df_test = test_df[test_df['label'].isin([0, 3])]","metadata":{"execution":{"iopub.status.busy":"2024-02-01T11:31:00.738504Z","iopub.execute_input":"2024-02-01T11:31:00.739232Z","iopub.status.idle":"2024-02-01T11:31:00.745807Z","shell.execute_reply.started":"2024-02-01T11:31:00.739203Z","shell.execute_reply":"2024-02-01T11:31:00.744755Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"df_test['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T11:31:01.481196Z","iopub.execute_input":"2024-02-01T11:31:01.481958Z","iopub.status.idle":"2024-02-01T11:31:01.490895Z","shell.execute_reply.started":"2024-02-01T11:31:01.481920Z","shell.execute_reply":"2024-02-01T11:31:01.489606Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"label\n0    25\n3    23\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"root_dir = \"/kaggle/input/mrnet-v1/MRNet-v1.0/\"","metadata":{"execution":{"iopub.status.busy":"2024-02-01T11:31:03.997110Z","iopub.execute_input":"2024-02-01T11:31:03.997584Z","iopub.status.idle":"2024-02-01T11:31:04.002511Z","shell.execute_reply.started":"2024-02-01T11:31:03.997546Z","shell.execute_reply":"2024-02-01T11:31:04.001295Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"test_set= MRDataset(root_dir,plane=\"axial\",train=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T11:31:07.197282Z","iopub.execute_input":"2024-02-01T11:31:07.197688Z","iopub.status.idle":"2024-02-01T11:31:07.202552Z","shell.execute_reply.started":"2024-02-01T11:31:07.197654Z","shell.execute_reply":"2024-02-01T11:31:07.201513Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"N_WAY = 2  # Number of classes in a task\nN_SHOT = 8  # Number of images per class in the support set\nN_QUERY = 10  # Number of images per class in the query set\nN_EVALUATION_TASKS = 100\n\n# The sampler needs a dataset with a \"get_labels\" method. Check the code if you have any doubt!\n\ntest_sampler = TaskSampler(\n    test_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_EVALUATION_TASKS\n)\n\ntest_loader = DataLoader(\n    test_set,\n    batch_sampler=test_sampler,\n    num_workers=4,\n    pin_memory=True,\n    collate_fn=test_sampler.episodic_collate_fn,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T11:31:07.877147Z","iopub.execute_input":"2024-02-01T11:31:07.877916Z","iopub.status.idle":"2024-02-01T11:31:07.884230Z","shell.execute_reply.started":"2024-02-01T11:31:07.877879Z","shell.execute_reply":"2024-02-01T11:31:07.883072Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"accuracy = evaluate(few_shot_classifier, test_loader)\nprint(f\"Average accuracy : {(100 * accuracy):.2f} %\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T11:31:19.714834Z","iopub.execute_input":"2024-02-01T11:31:19.715206Z","iopub.status.idle":"2024-02-01T11:34:14.486095Z","shell.execute_reply.started":"2024-02-01T11:31:19.715174Z","shell.execute_reply":"2024-02-01T11:34:14.484924Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [02:54<00:00,  1.75s/it, accuracy=0.81]","output_type":"stream"},{"name":"stdout","text":"Average accuracy : 81.00 %\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}